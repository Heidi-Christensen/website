---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

{% include base_path %}
<p>My research is centered on the development of <b>AI and speech technology for healthcare</b>. I am particularly interested in how spontaneous, conversational speech can serve as a window into a person’s cognitive and neurological health.</p>

<h3>Automated Clinical Assessment & CognoSpeak™</h3>
<p>A primary focus of my current work is the <a href="https://www.cognospeak.com">CognoSpeak™</a> system. CognoSpeak is an automated, web-based tool designed to help clinicians detect early signs of cognitive impairment and dementia through natural conversation.</p>

<p>Recent breakthroughs (2025-2026) have expanded this work into:</p>
<ul>
    <li><b>Clinical Utility:</b> Our latest study in the <i>IEEE Journal of Biomedical and Health Informatics</i> (2025) demonstrates CognoSpeak’s effectiveness in remote, real-world diagnostic settings. You can read more about the clinical applications on the <a href="https://www.cognospeak.com/research">CognoSpeak Research page</a>.</li>
    <li><b>Diagnostic Breadth:</b> We are currently adapting these speech-based biomarkers for the detection of <b>Stroke-related cognitive changes</b> and <b>Motor Neurone Disease (MND)</b>, supported by recent funding from the Rosetrees Trust.</li>
</ul>

<h3>The PROCESS Data Challenge & Open Science</h3>
<p>In 2025, my team and I organized the <b>PROCESS Challenge</b> (Early dementia detection using multiple spontaneous speech prompts) as part of the IEEE ICASSP conference. The challenge attracted 50 international participating teams and focused on advancing the state-of-the-art in detecting early cognitive decline from real-world, conversational speech data.</p>

<p>I am a strong advocate for <b>open science</b> and the belief that high-quality clinical datasets should be made available to the wider research community to accelerate innovation in healthcare AI. My team and I are committed to making data available through platforms like Zenodo, ensuring that non-proprietary audio and metadata can benefit the global research community while maintaining the highest ethical and privacy standards.</p>

<h3>Speech and Language Biomarkers</h3>
<p>Beyond dementia, my lab investigates the intersection of <b>natural language understanding (NLU)</b> and clinical diagnostics. This includes:</p>
<ul>
    <li><b>Primary Progressive Aphasia:</b> Automated sub-typing of PPA using cross-attention systems (see our <i>Interspeech 2025</i> paper).</li>
    <li><b>Inclusive AI:</b> Ensuring that speech-based diagnostics are accent-agnostic and robust across diverse demographic groups.</li>
    <li><b>Multimodal Analysis:</b> Integrating speech with visual cues, such as eye-blink rates and facial expressions, to increase diagnostic sensitivity.</li>
</ul>

<h3>Key Recent Publications</h3>
<p>For a full list of my 120+ publications, please visit my <a href="https://scholar.google.com/citations?user=f_kLp7oAAAAJ">Google Scholar profile</a>. Selected recent highlights include:</p>
<ul>
    <li><b>Pahar, M.</b>, Mirheidari, B., Blackburn, D., O’Malley, R., Walker, T., Reuber, M., & <b>Christensen, H.</b> (2025). "CognoSpeak: an automatic, remote assessment of early cognitive decline in real-world conversational speech." <i>IEEE Journal of Biomedical and Health Informatics</i>.</li>
    <li><b>Tao, F.</b>, Mirheidari, B., Pahar, M., Blackburn, D., & <b>Christensen, H.</b> (2025). "Early dementia detection using multiple spontaneous speech prompts: The PROCESS challenge." <i>Proc. ICASSP 2025</i>.</li>
    <li><b>Pan, Y.</b>, Mirheidari, B., Tu, Z., O'Malley, R., Walker, T., Blackburn, D., & <b>Christensen, H.</b> (2025). "A Two-Step Attention-Based Feature Combination Cross-Attention System for Speech-Based Dementia Detection." <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing</i>.</li>
    <li><b>Mirheidari, B.</b>, Walker, T., Blackburn, D., & <b>Christensen, H.</b> (2025). "Automatic Detection and Sub-typing of Primary Progressive Aphasia from Speech." <i>Proc. Interspeech 2025</i>.</li>
</ul>